{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1246182,"sourceType":"datasetVersion","datasetId":715500}],"dockerImageVersionId":30776,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install git+https://github.com/huggingface/transformers","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-28T07:45:50.682747Z","iopub.execute_input":"2024-09-28T07:45:50.683360Z","iopub.status.idle":"2024-09-28T07:46:41.443579Z","shell.execute_reply.started":"2024-09-28T07:45:50.683326Z","shell.execute_reply":"2024-09-28T07:46:41.442487Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/huggingface/transformers\n  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-5lgwxqti\n  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-5lgwxqti\n  Resolved https://github.com/huggingface/transformers to commit 2e24ee4dfa39cc0bc264b89edbccc373c8337086\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.46.0.dev0) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers==4.46.0.dev0) (0.25.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.46.0.dev0) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.46.0.dev0) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.46.0.dev0) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.46.0.dev0) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.46.0.dev0) (2.32.3)\nCollecting tokenizers<0.21,>=0.20 (from transformers==4.46.0.dev0)\n  Downloading tokenizers-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.46.0.dev0) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.46.0.dev0) (4.66.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.46.0.dev0) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.46.0.dev0) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers==4.46.0.dev0) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.46.0.dev0) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.46.0.dev0) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.46.0.dev0) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.46.0.dev0) (2024.8.30)\nDownloading tokenizers-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: transformers\n  Building wheel for transformers (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for transformers: filename=transformers-4.46.0.dev0-py3-none-any.whl size=9922875 sha256=1a5f6e6cf351d4d8c8d126a355fcf81a55f5810cb262e6cd735bec5cb9e2a516\n  Stored in directory: /tmp/pip-ephem-wheel-cache-0hcj2nkq/wheels/c0/14/d6/6c9a5582d2ac191ec0a483be151a4495fe1eb2a6706ca49f1b\nSuccessfully built transformers\nInstalling collected packages: tokenizers, transformers\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.19.1\n    Uninstalling tokenizers-0.19.1:\n      Successfully uninstalled tokenizers-0.19.1\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.44.2\n    Uninstalling transformers-4.44.2:\n      Successfully uninstalled transformers-4.44.2\nSuccessfully installed tokenizers-0.20.0 transformers-4.46.0.dev0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import Qwen2VLForConditionalGeneration, AutoTokenizer, AutoProcessor","metadata":{"execution":{"iopub.status.busy":"2024-09-28T07:46:41.445383Z","iopub.execute_input":"2024-09-28T07:46:41.445731Z","iopub.status.idle":"2024-09-28T07:46:59.098675Z","shell.execute_reply.started":"2024-09-28T07:46:41.445693Z","shell.execute_reply":"2024-09-28T07:46:59.097703Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"model = Qwen2VLForConditionalGeneration.from_pretrained(\n    \"Qwen/Qwen2-VL-7B-Instruct\",\n    torch_dtype=\"auto\",\n    device_map=\"auto\",\n)\n\nprocessor = AutoProcessor.from_pretrained(\n    \"Qwen/Qwen2-VL-7B-Instruct\"\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-28T07:47:37.068752Z","iopub.execute_input":"2024-09-28T07:47:37.069455Z","iopub.status.idle":"2024-09-28T07:49:58.433564Z","shell.execute_reply.started":"2024-09-28T07:47:37.069414Z","shell.execute_reply":"2024-09-28T07:49:58.432677Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"94aaaa4f1c5c4344af3b82ee0ed7e872"}},"metadata":{}},{"name":"stderr","text":"Unrecognized keys in `rope_scaling` for 'rope_type'='default': {'mrope_section'}\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/56.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d5584b605a64ae0997f77914a396439"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20540a03c9b94500ba4e953fde420696"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00005.safetensors:   0%|          | 0.00/3.90G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"986e0d8241e340509f0bdc60bfef11cc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00005.safetensors:   0%|          | 0.00/3.86G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b7efb78a3814b9fb5dfed2ebe5a3a5c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00005.safetensors:   0%|          | 0.00/3.86G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5085775c25f8410abf15ab11a808d157"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00005.safetensors:   0%|          | 0.00/3.86G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62c38e9b7344460c822f6291b5281de3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00005-of-00005.safetensors:   0%|          | 0.00/1.09G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fab37f92228e4ffa966f4ee722144832"}},"metadata":{}},{"name":"stderr","text":"`Qwen2VLRotaryEmbedding` can now be fully parameterized by passing the model config through the `config` argument. All other arguments will be removed in v4.46\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25da273dd96d40178758968d5b54e684"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/244 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0acbd7a2ccb34cbdbb06642c56fd324e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/347 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff877add673f4e95b87dc9ded6d4a7c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/4.19k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d3f7b9d7b6c4a298e71167d200b667c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0a1d0d1e4bb46929010ca76f307dc1c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a0452d4c23eb415f801814296b141d81"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c4a160bbde9439f99e58a836574a8b4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"chat_template.json:   0%|          | 0.00/1.05k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e8667661551046a9913f43e0dcbacbbb"}},"metadata":{}}]},{"cell_type":"code","source":"from PIL import Image\nimport requests","metadata":{"execution":{"iopub.status.busy":"2024-09-28T07:49:58.435359Z","iopub.execute_input":"2024-09-28T07:49:58.435716Z","iopub.status.idle":"2024-09-28T07:49:58.440413Z","shell.execute_reply.started":"2024-09-28T07:49:58.435678Z","shell.execute_reply":"2024-09-28T07:49:58.439257Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import os\nimport pandas as pd\nfrom PIL import Image\nfrom tqdm import tqdm  # Import tqdm for the progress bar\n\n# Assuming you have already defined `processor` and `model` in your code\n\n# Step 1: Define the folder containing images\nimage_folder = '/kaggle/input/facebook-hateful-meme-dataset/data/img'  # Replace with your Kaggle image folder path\n\n# Step 2: Initialize an empty list to store the results\nresults = []\n\n# Step 3: Get a sorted list of valid image files in ascending order\nvalid_images = sorted([image_name for image_name in os.listdir(image_folder) \n                       if image_name.endswith(('.png', '.jpg', '.jpeg'))])\n\n# Step 4: Define start and end indices for processing images\nstart_index = 0\nend_index = 1000\n\n# Step 5: Process each image in the specified range\nfor index in tqdm(range(start_index, min(end_index, len(valid_images))), desc=\"Processing Images\"):\n    image_name = valid_images[index]  # Get the image name based on the current index\n    image_path = os.path.join(image_folder, image_name)  # Construct the full image path\n    \n    # Open the image\n    image = Image.open(image_path)\n\n    # Prepare the messages for the model\n    messages = [\n        {\n            \"role\": \"user\",\n            \"content\": [\n                {\n                    \"type\": \"image\",\n                },\n                {\n                    \"type\": \"text\",\n                    \"text\": \"Please extract the text from the image.\",\n                },\n            ],\n        }\n    ]\n\n    text_prompt = processor.apply_chat_template(messages, add_generation_prompt=True)\n    inputs = processor(\n        text=[text_prompt],\n        images=[image],\n        padding=True,\n        return_tensors=\"pt\",\n    )\n\n    inputs = inputs.to(\"cuda\")\n\n    output_ids = model.generate(**inputs, max_new_tokens=1024)\n    generated_ids = [\n        output_ids[len(input_ids):]\n        for input_ids, output_ids in zip(inputs.input_ids, output_ids)\n    ]\n\n    output_text = processor.batch_decode(\n        generated_ids, skip_special_tokens=True, clean_up_tokenization_spaces=True\n    )\n\n    # Replace \\n with space\n    output_text = [text.replace('\\n', ' ') for text in output_text]\n\n    # Prepare final output\n    final_output = ' '.join(output_text)\n    \n    # Append the results with image name (id)\n    image_id = os.path.splitext(image_name)[0]  # Get the image name without extension\n    results.append({\"id\": image_id, \"text\": final_output})\n\n# Step 6: Create a DataFrame from the results\nresults_df = pd.DataFrame(results)\n\n# Step 7: Save the DataFrame to a CSV file\noutput_csv_path = '/kaggle/working/extracted_texts.csv'  # Output CSV file path\nresults_df.to_csv(output_csv_path, index=False)\n\nprint(f\"Text extraction completed. Results saved to {output_csv_path}.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-28T08:05:28.420517Z","iopub.execute_input":"2024-09-28T08:05:28.421322Z","iopub.status.idle":"2024-09-28T08:05:56.581174Z","shell.execute_reply.started":"2024-09-28T08:05:28.421271Z","shell.execute_reply":"2024-09-28T08:05:56.580237Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"Processing Images: 100%|██████████| 5/5 [00:28<00:00,  5.63s/it]","output_type":"stream"},{"name":"stdout","text":"Text extraction completed. Results saved to /kaggle/working/extracted_texts.csv.\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}